{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_x = 680 #FIXME\n",
    "img_size_y = 454 #FIXME\n",
    "\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    try:\n",
    "        img_arr = cv2.imread(data_dir) #convert BGR to RGB format, since imread returns BGR\n",
    "        resized_arr = cv2.resize(img_arr, (img_size_x, img_size_y))[...,::-1] # Reshaping images to preferred size\n",
    "        data = resized_arr\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = get_data('./Images/location/background2.jpg')\n",
    "image = get_data('./Images/location/image2.jpg')\n",
    "#background\n",
    "#print(background[3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"image\", background[...,::-1])\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"image\", image[...,::-1])\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta-e metrix  \n",
    "\n",
    "#### Rank system (0-100)\n",
    "<= 1.0: Not perceptible by the human eye  \n",
    "1-2: Perceptible through close observation  \n",
    "2-10: Perceptible at a glance  \n",
    "11-49: Colors are more similar than the opposite  \n",
    "100: Colors are exactly the opposite  \n",
    "\n",
    "http://zschuessler.github.io/DeltaE/learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(background.shape)\n",
    "#delta_e_data = np.zeros(background.shape)\n",
    "for row in range(background.shape[0]): #row\n",
    "    for col in range(background.shape[1]): #col\n",
    "        #~4s to convert to rgb\n",
    "        color1_rgb = sRGBColor(background[row,col,0], background[row,col,1], background[row,col,2], is_upscaled=True);\n",
    "        color2_rgb = sRGBColor(image[row,col,0], image[row,col,1], image[row,col,2], is_upscaled=True);\n",
    "        #~24s to convert to labcolor\n",
    "        color1_lab = convert_color(color1_rgb, LabColor);\n",
    "        color2_lab = convert_color(color2_rgb, LabColor);\n",
    "        #~50s to figure out delta_e\n",
    "        delta_e = delta_e_cie2000(color1_lab, color2_lab); \n",
    "        #delta_e_data[row, col] = [delta_e, delta_e, delta_e]\n",
    "        if (delta_e <= 30):\n",
    "            data[row,col] = [255,255,255] #white for similar\n",
    "        elif (delta_e > 30):\n",
    "            data[row,col] = [0,0,0] #black for different\n",
    "data = data.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "1. Color comparison, using delta_E (~80s)\n",
    "2. Low noise, use a white board and convert anything that isn't white to black (theoretically much faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"image\", data)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Center of Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.60311080041942 514.2543254106959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "immat = copy.deepcopy(data)\n",
    "(X,Y) = (background.shape[0], background.shape[1])\n",
    "m = np.zeros((X, Y))\n",
    "'''\n",
    "for x in range(X):\n",
    "    for y in range(Y):\n",
    "        if immat[x,y,0] != 255 and immat[x,y,1] != 255 and immat[x,y,2] != 255:\n",
    "            m[x,y] = 0;\n",
    "        else:\n",
    "            m[x,y] = 1; \n",
    "'''\n",
    "m = np.sum(immat, -1) < 255*3\n",
    "m = m / np.sum(np.sum(m))\n",
    "\n",
    "# marginal distributions\n",
    "dx = np.sum(m, 1)\n",
    "dy = np.sum(m, 0)\n",
    "\n",
    "# expected values\n",
    "cx = np.sum(dx * np.arange(X))\n",
    "cy = np.sum(dy * np.arange(Y))\n",
    "\n",
    "data[math.ceil(cx)][math.ceil(cy)] = [255,0,0]\n",
    "print(cx,cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\", data[...,::-1]) #red dot in the center of mass\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining location from pixel number\n",
    "1. If we know much distance a pixel covers, we can figure out where the object is\n",
    "2. Will require some extra code, or use (0,0) as the bottom left relative to the camera\n",
    "3. Draw a black line measuring 1 cm, and use code to determine how many pixels that is (run ONCE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
